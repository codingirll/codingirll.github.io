# 消息队列

场景：秒杀

秒杀中，消息队列会作为轻量级操作和重量级操作的分界线。轻量化包含请求校验，扣减库存，一般是内存操作，最多操作redis，可以支持高并发。重量级操作会创建订单、支付等，无法支持高并发。（如果超时取消，就用延时队列+乐观锁，如果用户是未支付就更新订单为已取消）

不用消息队列的缺点：

- 性能差：要等待下游全部返回，就算并发调用也比写入消息队列慢。

- 扩展性差：新增业务方可以自主订阅，同步调用的话上游要知道下游的接口，构造请求，解析响应，联调测试上线，效率特别低。（非要同步调用，可定义统一API，下游实现） 

- 可用性差，只要消息发送到消息队列就认为操作成功了（消息队列可靠性），如果同步调用，会出现部分失败问题更容易出错。



## 有序消息

解决的问题：有序性指的是，消费者处理消息的顺序要和生产者发送消息的顺序保持一致。kafka可以保证单个分区内天然是有序的，无序出现在不同分区之间。

- 最基础的方案是单分区，但消费者消费不过来会有消息积压，撑不住高并发。

- 多分区方案

  大部分业务场景要求的有序是业务内的有序，比如说同一个订单id的所有消息创建、支付、发货等有序，而不同订单之间是否有序根本无所谓。

  发送消息时不让kafka自动分配分区，而是显式指定。提取业务id进行哈希计算，对分区数取模得到分区号，保证一个业务id的消息发送到同一个分区。

  问题：

    1. 数据分布不均 用一致性哈希代替哈希。如果一部分业务生成的消息特别多，就在哈希环上多插入几个节点。

    2. 扩容短暂失序 新分区的消费者延迟启动，等旧分区积压消息被消费再说

## 消息积压

问题：消息生成速度大于消费速度，消息要等很久才能被消费。但是我们不能一直增加消费者，因为一个分区最多只能由一个消费者，而一个消费者可以消费多个分区。

方案：

1. 增加分区 分区数量确定：生产者QPS除以消费者QPS，考虑突发流量留一些余量
2. 增加一个新的Topic 消费者同时消费新老Topic的消息，老topic数据消耗完就停掉。
3. 消费者降级
4. 异步消费

`异步消费`

​把拉取消息和提交这种非常快速的操作交给消费者线程，把拉取的消息转发到线程池，线程池的线程会并发执行。但会遇到一些问题。	

- 消息丢失：如果消费者线程提交了，但是线程没处理就丢失了消息。可以采用批处理，消费者线程等10条消息处理完毕再批量提交。
- 重复消费：线程处理完但没提交就宕机了，要保证消费消息的逻辑是幂等的。
- 部分失败：要确保失败不会影响继续消费，可以重试几次，或者把消息丢回去。

## 消息丢失（可靠消息）

kafka有一个参数acks可以控制，什么情况下判断发送成功。

- 0发送给kafka客户端算成功
- 1写入主分区算成功
- all 写入主分区，同步给所有ISR是成功

消息丢失的情况

1. acks=0 broker根本没收到
2. acks=1 主节点宕机
3. acks=all ISR分区全崩了
4. 异步消费的时候，消费者线程提交了消息，转给工作线程却没处理完



解决方案：发送者一定发送+消息队列不丢失+消费者一定消费

> 促活平台通过本地消息表解决消息丢失问题，保证发送端一定发送了。
>
> 创建一张本地消息表Task表，包含要发送的消息。同一个事务中处理业务逻辑和更新tastk表操作。如果发送成功，就标记为已发送。没成功立刻重试。另外，有一个异步补偿机制，扫描Task表，没成功的重发。
>
> (本质是把分布式事务转化为本地事务+补偿机制。)

## 消息重复消费(幂等性)

为什么保证幂等？微服务系统为了可用性会引入重试机制，消息队列的消息会重复发送或重复消费。

重复消费出现的场景：

- 消费者消费消息后宕机，未提交，恢复后重复消费

- 生产者发送时超时重试

方案：

1. 利用数据库的唯一索引

业务表中有唯一索引，如果重复插入会出现唯一索引错误。

本地事务可以保证业务操作和插入唯一索引的一致性，否则只能追求最终一致性。

> 金币瓜分项目中，业务操作要调用资管接口，无法做本地事务。我先把报名信息插入有唯一索引限制的报名表中，状态标记为初始状态，然后调用资管接口，调用成功就标记为完成。
>
> 调用资管可能会失败，所以开一个异步检测脚本，定时扫描报名表和资管的表，以资管为准。如果发现资管已经转账成功，标记为已支付。如果没有转账成功，可以重试。

2. 布隆过滤器+redis+唯一索引

高并发幂等方案。数据库不太能撑住高并发，所以要想办法在使用唯一索引前削减流量。

  step1 一个请求过来，利用布隆过滤器判断有没有处理过，没有处理过肯定是没有处理，就直接处理，如果处理过可能出现假阳性。（bit array没有假阳性的问题，适用于自增主键的情况）

  step2 使用redis判断假阳性的问题，如果redis中存在key说明被处理过了。

  step3 最后使用数据库的唯一索引

  注意：
  
  * 请求处理时，要保证数据库先更新，然后再更新布隆过滤器和redis

  * redis的key过期时间根据重试时间来设置，留点余量就行。重试间隔大就不合适。

## kafka延迟消息

延迟队列里面的元素有一个过期时间，只有到期了才能取出来。

方案：

1. 定时任务

  注册一个定时任务，在多少分钟后将消息发送到消息队列。缺点是不支持高并发。

2. 引入延迟topic和延迟消费组

  创建一个延迟topic，有N个分区，每个分区是不同的延时时间。创建一个消费组消费延迟topic，每个分区对应一个消费者，消费组读取到消息会根据延迟时间来等待，等待完再发送到真正的业务topic上。

​	问题:

​		消费者先转发了再提交，重试了，数据不一致，需要消费方幂等。

​		延迟时间要预先设定好，且会出现负载不均衡，负载高的分区出现消息积压。
## 高性能

* 零拷贝　

  数据直接从磁盘由page cache发送到网卡，两个过程都说DMA拷贝，不用CPU，不用在用户态和内核态来回拷贝，减少了两次上下文切换和两次次CPU数据拷贝。

* page cache

  kafka不是将消息直接刷到磁盘，而是写入到page cahce，异步刷盘，减少了磁盘IO。

* 顺序写

  随机写因为要到处找，所以比顺序写慢多了。kafka的分区数据写入时用仅追加的方法写入日志文件，消费者消费也是根据偏移量做范围查询顺序读。

## 设计

从基础概念，生产者、消费者、broker和topic四个方面去想

topic：topic和业务对应，必须做分区，不做分区生产者和消费者都会出现并发竞争

topic是一张逻辑表，不同分区要散在不同的broker上可以对应分库分表后的物理表，自增主键对应偏移量。

生产者把消息写入分区表。

要保留消费者组，支持不同业务方消费同一个topic。一个分区只能有一个消费者，不同业务方是不同的消费者组，一个消费者组里面有多个消费者。

消费时记录一张消费情况表，包含消费组名字，分区和已消费的偏移量。消费者提交消息的时候，要修改偏移量。